# This MLP consists of N fully connected layers. 
# Size of the layers and number can be chosen, Please, change just numbers
# All layers use Relu activation function except output (softmax)
4       -   number of layers
Size    | Type
784     - input
128      - fully connected
64      - fully connected
32      - fully connected
10     - output (softmax)

