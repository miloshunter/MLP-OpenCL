# This MLP consists of N fully connected layers. 
# Size of the layers and number can be chosen, Please, change just numbers
# All layers use Relu activation function except output (softmax)
4       -   number of layers
Size    | Type
784     - input
1024      - fully connected
512      - fully connected
256      - fully connected
10     - output (softmax)

